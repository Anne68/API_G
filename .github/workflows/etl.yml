name: ETL Games (API + Scraping)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 5 * * *"   # 07:00 Paris

jobs:
  run-etl:
    runs-on: self-hosted
    defaults:
      run:
        shell: cmd   # ✅ exécute tout en CMD (pas de PowerShell)

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check Python on runner
        run: python --version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Build .env from secrets (CMD)
        run: |
          > .env echo RAWG_API_KEY=${{ secrets.RAWG_API_KEY }}
          >> .env echo DB_USER=${{ secrets.DB_USER }}
          >> .env echo DB_PASSWORD=${{ secrets.DB_PASSWORD }}
          >> .env echo DB_HOST=${{ secrets.DB_HOST }}
          >> .env echo DB_PORT=${{ secrets.DB_PORT }}
          >> .env echo DB_NAME=${{ secrets.DB_NAME }}
          >> .env echo DB_TABLE=${{ secrets.DB_TABLE }}
          >> .env echo LOG_LEVEL=INFO
          >> .env echo HTTP_TIMEOUT=20
          >> .env echo HTTP_RETRIES=3
          >> .env echo SCRAPE_ENABLED=${{ secrets.SCRAPE_ENABLED }}
          >> .env echo SCRAPE_CONFIG=scrape_sources.json

      # Optionnel : n'exécute que si le secret est renseigné
      - name: Write scrape_sources.json if provided
        if: ${{ secrets.SCRAPE_CONFIG_JSON != '' }}
        env:
          SCRAPE_CONFIG_JSON: ${{ secrets.SCRAPE_CONFIG_JSON }}
        run: |
          python -c "import os,io,sys; open('scrape_sources.json','w',encoding='utf-8').write(os.environ.get('SCRAPE_CONFIG_JSON',''))"
          echo scrape_sources.json created from secret

      - name: Run ETL (50 nouveaux jeux + update)
        run: python etl_games.py --limit 50

      - name: Upload log (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: etl-logs
          path: etl_games.log
          if-no-files-found: ignore
